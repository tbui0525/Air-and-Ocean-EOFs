{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb8c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = \"C:\\\\Utilities\\\\Python\\\\Anaconda\\\\Library\\\\share\"; #fixr\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c71a3f",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1156318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990,\n",
       "       1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,\n",
       "       2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
       "       2013, 2014, 2015])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.arange(1980,2016)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this downloads data from GODAS website if you do not already have data downloaded (it's under data)\n",
    "for year in years:\n",
    "    url = 'https://downloads.psl.noaa.gov/Datasets/godas/pottmp.'+str(year)+'.nc'\n",
    "    r = requests.get(url, allow_redirects = True)\n",
    "    open('pottmp.'+str(year)+'.nc', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e81d7",
   "metadata": {},
   "source": [
    "# Compiling and Reformatting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/air.mon.meanv3.nc'\n",
    "air_data = nc.Dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab988ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_lats = air_data.variables['lat'][:]\n",
    "air_lons = air_data.variables['lon'][:]\n",
    "time = air_data.variables['time'][:]\n",
    "air = air_data.variables['air'][(1980-1836)*12::12] #only extract Jan 1980-Jan 2015\n",
    "levels = air_data.variables['level'][:]\n",
    "xxair, yyair = np.meshgrid(air_lons, air_lats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_data = []\n",
    "for year in years:\n",
    "    file = 'data/pottmp.'+str(year)+'.nc'\n",
    "    water_data.append(nc.Dataset(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_lons = np.array(water_data[0].variables['lon'][:])\n",
    "water_lats = np.array(water_data[0].variables['lat'][:])\n",
    "depths =WaterData[0].variables['level'][:]\n",
    "xxwater, yywater = np.meshgrid(waterlons, waterlats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ae25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_temps = []\n",
    "for i in range(0, len(water_data)):\n",
    "    annual_air = np.array(air[i].flatten()).tolist()\n",
    "    annual_water = water_data[i].variables['pottmp'][0] #Jan = 0, Feb = 1... Dec = 11\n",
    "    annual_water = np.array(annual_water[0].flatten()).tolist()  #only first water layer\n",
    "    jan_temps.append(annual_air + annual_water)\n",
    "jan_temps = np.array(jan_temps).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ffad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces with Nan because of how GODAS data is formatted\n",
    "for i in range(air[0].size, jan_temps.shape[0]):\n",
    "    for j in range(0, jan_temps.shape[1]):\n",
    "        if (jan_temps[i,j] < 0):\n",
    "            jan_temps[i,j] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3efdd",
   "metadata": {},
   "source": [
    "# Preweighted Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category = RuntimeWarning) #deals with nans and dividing by 0 possibilities\n",
    "    clim = np.nanmean(jan_temps, axis =1)\n",
    "    sdev = np.nanstd(jan_temps, axis =1)\n",
    "clim = np.reshape(clim, (clim.size,1))\n",
    "sdev = np.reshape(sdev, (sdev.size,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardized anomalies\n",
    "np.seterr(divide='ignore', invalid='ignore') #to deal with divide by 0 errors and NaNs\n",
    "stnd_anom = (jan_temps - clim)/ sdev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e354a",
   "metadata": {},
   "source": [
    "# Weighted Computations\n",
    "\n",
    "$$ \\sqrt{c_p \\rho \\Delta d_{ij}  \\cos{\\phi}\\Delta \\theta \\Delta \\phi }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats_air = np.array(yyair).flatten().tolist()\n",
    "lats_water = np.array(yywater).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b118cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats_weighed = []\n",
    "for i in range(levels.size):\n",
    "    lats_weighed += lats_air\n",
    "lats_weighed += lats_water\n",
    "lats_weighed = np.array(lats_weighed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_area = np.sqrt(np.cos(lats_weighed *np.pi/180))\n",
    "weighted_area = np.reshape(weighted_area, (weighted_area,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a969e8",
   "metadata": {},
   "source": [
    "### Airheights (approximated with hypsometric equations and assumed $P_0 = 1013.25$ mbar and $h_0 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8d9ec",
   "metadata": {},
   "source": [
    "$$ P_n = P_{n-1} e^{\\frac{-gM(h_n-h_{n-1})}{RT}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a260d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_clim =clim[0:air[0].size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "p = 101325e-2 #assumed p0\n",
    "r = 8.31432 #gas constant\n",
    "m = 0.0289644 \n",
    "g = 9.8 #gravitational constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_heights = []\n",
    "for i in range(0, 360*181):\n",
    "    air_heights.append(r*air_clim[i]/(-g*m)*np.log(levels[int(i/(181*360))]/p))\n",
    "for i in range(181*360, airclim.size):\n",
    "    air_heights.append(r*air_clim[i]/(-g*m)*\n",
    "                       np.log(levels[int(i/(181*360))]/levels[int(i/(181*360))-1]) +air_heights[i-(181*360)])\n",
    "air_heights = np.array(air_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334b58a",
   "metadata": {},
   "source": [
    "### Thickness $$ \\Delta d_{ij} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_thickness = [5]\n",
    "thickness = np.empty([stnd_anom.shape[0], 1])\n",
    "thickness[0:181*360] = air_heights[0:181*360]\n",
    "for i in range(181*360, air[0].size):\n",
    "    thickness[i] = air_heights[i] - air_heights[i-181*360]\n",
    "for j in range(air[0].size, stnd_anom.shape[0]):\n",
    "    thickness[j] = water_thickness[int((j-air[0].size)/(360*418))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c0911",
   "metadata": {},
   "source": [
    "### Gridbox size\n",
    "$$ \\Delta \\theta \\Delta \\phi$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "airgrid = 1\n",
    "watergrid = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSize = np.empty([stnd_anom.shape[0], 1])\n",
    "for i in range(0, air[0].size):\n",
    "    gridSize[i] = airgrid\n",
    "for j in range(air[0].size, gridSize.size):\n",
    "    gridSize[j] = watergrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5824474",
   "metadata": {},
   "source": [
    "### Density $$\\rho$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9448af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_density = 1000\n",
    "density = np.empty([stnd_anom.shape[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5960",
   "metadata": {},
   "source": [
    "Air density calculated using the NASA's Earth Atmosphere Model with given pressure and temperature.\n",
    "https://www.grc.nasa.gov/www/k-12/airplane/atmosmet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,air[0].size):\n",
    "    density[i] =  levels[int(i/(181*360))]/(2.869*clim[i])\n",
    "for j in range(air[0].size,density.size):\n",
    "    density[j] = water_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02a666",
   "metadata": {},
   "source": [
    "### Heat Capacity $$c_p$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_air = 1.005\n",
    "cp_water = 4.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e51534",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatCap = np.empty([weightedAnom.shape[0], 1])\n",
    "for i in range(0, air[0].size):\n",
    "    heatCap[i] = cp_air\n",
    "for j in range(air[0].size, gridSize.size):\n",
    "    heatCap[j] = cp_water"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3eafe4",
   "metadata": {},
   "source": [
    "## Putting all the different weights together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96587e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vweighted_anom = stnd_anom * weighted_area * np.sqrt(thickness) * np.sqrt(density) * np.sqrt(heatCap) * np.sqrt(gridSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b057243",
   "metadata": {},
   "source": [
    "# EOF computation (Geometric and Physical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71798538",
   "metadata": {},
   "source": [
    "### Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96126eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = vweighted_anom)\n",
    "dropna = df.dropna()\n",
    "No_Nan_Anom = dropna.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = np.matmul(No_Nan_Anom.T, No_Nan_Anom)\n",
    "eigenvalues, eigenvectors = scipy.linalg.eig(Sigma)\n",
    "eigenvectors = eigenvectors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e884e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the eigenvalues in descending order\n",
    "index = np.argsort(eigenvalues)[::-1]\n",
    "eigvals = engenvalues[index]\n",
    "eigvecs = eigenvectors[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval = np.arange(eigvales.shape[0])+1\n",
    "cumulative_eval = np.cumsum(eigvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853edd2",
   "metadata": {},
   "source": [
    "### Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30., 14.))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "p1, = plt.plot(num_eval,(eigvals/cumulative_eval[-1])*100, 'b', marker = 'o',label = 'Percentage Variance')\n",
    "ax.set_ylabel(\"Percentage Variance\")\n",
    "ax.yaxis.label.set_color('blue')\n",
    "ax.tick_params('y', colors='b')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "p2, = plt.plot(num_eval,(cumulative_eval/cumulative_eval[-1])*100,'r', marker = 'x',label = 'Cumulative Percentage Variance')\n",
    "ax2.tick_params('y', colors='r')\n",
    "ax2.set_ylabel(\"Cumulative Percentage Variance\")\n",
    "ax2.yaxis.label.set_color('red')\n",
    "\n",
    "plt.legend(handles=[p1,p2],loc='center right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42c5bf",
   "metadata": {},
   "source": [
    "### EOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOFS = []\n",
    "\n",
    "for j in range(0,vweightedanom.shape[1]):\n",
    "        EOFS.append(np.matmul(vweighted_anom, eigvecs[j])/np.linalg.norm(np.matmul(No_Nan_Anom, eigvecs[j])))\n",
    "EOF1 = np.array(EOFS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90fcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physical EOFs\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "PhysicalEOFs = EOF1/(weightedA * np.sqrt(thickness) * np.sqrt(density) * np.sqrt(heatCap) * np.sqrt(gridSize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
